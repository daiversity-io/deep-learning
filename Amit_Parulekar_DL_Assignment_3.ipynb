{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaDl7kau7BRx"
   },
   "source": [
    "#### Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_I_1FuG7BR0"
   },
   "source": [
    "Predict the political party from the tweet text and the handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVp0YoSW7BR1"
   },
   "source": [
    "#### Data description\n",
    "This dataset has three columns - label (party name), twitter handle, tweet text\n",
    "\n",
    "\n",
    "#### Problem Description:\n",
    "\n",
    "Design a feed forward deep neural network to predict the political party using the pytorch or tensorflow. \n",
    "Build two models\n",
    "\n",
    "1. Without using the handle\n",
    "\n",
    "2. Using the handle\n",
    "\n",
    "\n",
    "#### Deliverables\n",
    "\n",
    "- Report the performance on the test set.\n",
    "\n",
    "- Try multiple models and with different hyperparameters. Present the results of each model on the test set. No need to create a dev set.\n",
    "\n",
    "- Experiment with:\n",
    "    -L2 and dropout regularization techniques\n",
    "    -SGD, RMSProp and Adamp optimization techniques\n",
    "\n",
    "\n",
    "\n",
    "- Creating a fixed-sized vocabulary: Give a unique id to each word in your selected vocabulary and use it as the input to the network\n",
    "\n",
    "    - Option 1: Feedforward networks can only handle fixed-sized inputs. You can choose to have a fixed-sized K words from the tweet text (e.g. the first K word, randomly selected K word etc.). K can be a hyperparameter. \n",
    "\n",
    "    - Option 2: you can choose top N (e.g. N=1000) frequent words from the dataset and use an N-sized input layer. If a word is present in a tweet, pass the id, 0 otherwise\n",
    "    \n",
    "    -  Clearly state your design choices and assumptions. Think about the pros and cons of each option.\n",
    "\n",
    " \n",
    "\n",
    "<b> Tabulate your results, either at the end of the code file or in the text box on the submission page. The final result should have:</b>\n",
    "\n",
    "1. Experiment description\n",
    "\n",
    "2. Hyperparameter used and their values\n",
    "\n",
    "3. Performance on the test set\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "NZPdeTRj8fuu",
    "outputId": "8dc3ee25-ab1e-4c1b-aff6-5c9c1e9f77a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party         Handle                                              Tweet\n",
       "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...\n",
       "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...\n",
       "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...\n",
       "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...\n",
       "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June..."
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv', index_col=0, error_bad_lines=False)\n",
    "test_df = pd.read_csv('test.csv', index_col=0, error_bad_lines=False)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Apn82RX684pC",
    "outputId": "6188e2af-fe29-4335-bc74-75c77fc1d2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Democrat' nan 'Republican']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.Party.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "iCHGx7zKBhzK",
    "outputId": "3143e14d-37bf-40be-ef6d-65cbeb71218f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Democrat' 'Republican']\n"
     ]
    }
   ],
   "source": [
    "print(test_df.Party.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ZHB-n2oP6lvl",
    "outputId": "e05df7b7-d3a8-4715-b0f9-4ca498c7759a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Democrat' 'Republican']\n"
     ]
    }
   ],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "print(train_df.Party.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "fDu2Gw3W8kqr",
    "outputId": "6e45d9e4-305f-4892-c239-e1d8d1acca76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Party         Handle                                              Tweet\n",
       "0      1  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...\n",
       "1      1  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...\n",
       "2      1  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...\n",
       "3      1  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...\n",
       "4      1  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June..."
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Party.replace(['Democrat', 'Republican'], [1, 0], inplace=True)\n",
    "test_df.Party.replace(['Democrat', 'Republican'], [1, 0], inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFD9MzWzD2_h"
   },
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "#apply preprocess_text to remove HTML tags, punctuations and numbers.\n",
    "train_sentences = list(train_df.Tweet)\n",
    "for sen in train_sentences:\n",
    "    X_train.append(preprocess_text(sen))\n",
    "\n",
    "y_train = train_df.Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6Pn3QWFFJEE"
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "#apply preprocess_text to remove HTML tags, punctuations and numbers.\n",
    "test_sentences = list(test_df.Tweet)\n",
    "for sen in test_sentences:\n",
    "    X_test.append(preprocess_text(sen))\n",
    "\n",
    "y_test = test_df.Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suW5C0iVFS67"
   },
   "outputs": [],
   "source": [
    "# create a word-to-index dictionary by fitting it on X_train to see all vocab\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# perform the tokenization (replace each word by its corresponding index)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LtLlgq5pcv5J",
    "outputId": "9c8e7cfb-d627-4af4-bfab-1dc6d3995ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Maximum sentence length in the training data\n",
    "print(len(max(X_train, key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trNyL1MzFW_T"
   },
   "outputs": [],
   "source": [
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1 #this variable will be used later\n",
    "\n",
    "# Experimented with 100, 50, 30 and finally 20.\n",
    "maxlen = 20 # maximum length of the sentence in WORDS\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "9rScxqAIFyjj",
    "outputId": "dbfd2c29-e690-4694-ca16-b9b818374b6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>209</td>\n",
       "      <td>1003</td>\n",
       "      <td>145</td>\n",
       "      <td>4</td>\n",
       "      <td>3022</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>3023</td>\n",
       "      <td>701</td>\n",
       "      <td>152</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>30924</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>15880</td>\n",
       "      <td>1960</td>\n",
       "      <td>1569</td>\n",
       "      <td>2630</td>\n",
       "      <td>15881</td>\n",
       "      <td>5121</td>\n",
       "      <td>1160</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>992</td>\n",
       "      <td>1316</td>\n",
       "      <td>30</td>\n",
       "      <td>1545</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>1160</td>\n",
       "      <td>20320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9819</td>\n",
       "      <td>1545</td>\n",
       "      <td>8526</td>\n",
       "      <td>18</td>\n",
       "      <td>854</td>\n",
       "      <td>2863</td>\n",
       "      <td>41</td>\n",
       "      <td>836</td>\n",
       "      <td>5294</td>\n",
       "      <td>404</td>\n",
       "      <td>7</td>\n",
       "      <td>6951</td>\n",
       "      <td>55</td>\n",
       "      <td>41</td>\n",
       "      <td>9820</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>20321</td>\n",
       "      <td>109</td>\n",
       "      <td>13</td>\n",
       "      <td>1545</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>193</td>\n",
       "      <td>13</td>\n",
       "      <td>30925</td>\n",
       "      <td>499</td>\n",
       "      <td>30926</td>\n",
       "      <td>30927</td>\n",
       "      <td>20321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>30928</td>\n",
       "      <td>854</td>\n",
       "      <td>1004</td>\n",
       "      <td>1663</td>\n",
       "      <td>10</td>\n",
       "      <td>2293</td>\n",
       "      <td>238</td>\n",
       "      <td>969</td>\n",
       "      <td>1121</td>\n",
       "      <td>1935</td>\n",
       "      <td>402</td>\n",
       "      <td>20322</td>\n",
       "      <td>1422</td>\n",
       "      <td>1545</td>\n",
       "      <td>15882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4      5   ...    14     15     16     17     18   19\n",
       "0  21    209  1003   145     4   3022  ...     1     39      3      2  30924  424\n",
       "1   9  15880  1960  1569  2630  15881  ...  1545      8     90   1160  20320    0\n",
       "2   9   9819  1545  8526    18    854  ...    41   9820     31      0      0    0\n",
       "3   9  20321   109    13  1545     62  ...   499  30926  30927  20321      0    0\n",
       "4   9  30928   854  1004  1663     10  ...  1545  15882      0      0      0    0\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAwexGoSeiju"
   },
   "source": [
    "# Model 1\n",
    "Without using the \"Handle\" feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nlRjAdl1EtW"
   },
   "source": [
    "A) Trying a normal feedforward deep neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "uUxYWdELGRDk",
    "outputId": "5b731ca3-93e2-432c-a400-d1c771e329f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 20)            2291400   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,572,745\n",
      "Trainable params: 281,345\n",
      "Non-trainable params: 2,291,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 20, input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['acc'], )\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "epGFoPTrGsnD",
    "outputId": "20099b4d-86fc-4f64-9c50-3e3eff201aed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "285/285 [==============================] - 3s 11ms/step - loss: 0.6882 - acc: 0.5348\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 3s 11ms/step - loss: 0.6755 - acc: 0.5726\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 3s 10ms/step - loss: 0.6355 - acc: 0.6319\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 3s 10ms/step - loss: 0.5187 - acc: 0.7383\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 3s 10ms/step - loss: 0.3770 - acc: 0.8266\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 3s 10ms/step - loss: 0.2493 - acc: 0.8925\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 3s 10ms/step - loss: 0.1711 - acc: 0.9302\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 3s 10ms/step - loss: 0.1295 - acc: 0.9479\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 3s 10ms/step - loss: 0.0926 - acc: 0.9635\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 3s 10ms/step - loss: 0.0819 - acc: 0.9674\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=256, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "OQtuM30tI6X7",
    "outputId": "71f3738a-37b6-4551-93b7-6f654830f36d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 1s 2ms/step - loss: 2.1772 - acc: 0.5576\n",
      "Test Accuracy: 0.5576278567314148\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PBforSs1POu"
   },
   "source": [
    "B) Adding dropout regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "lIDnl5GHerdF",
    "outputId": "cdd53a2d-ddba-48dd-de37-c8ff11768fd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 32)            3666240   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               328192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,070,465\n",
      "Trainable params: 404,225\n",
      "Non-trainable params: 3,666,240\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 32, input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "d-tKwIgdgStU",
    "outputId": "dd7cc126-3d58-4c2d-8265-b97c9bac3588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.6916 - acc: 0.5168\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.6896 - acc: 0.5310\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.6884 - acc: 0.5402\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.6863 - acc: 0.5464\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.6855 - acc: 0.5493\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.6839 - acc: 0.5530\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.6819 - acc: 0.5562\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.6796 - acc: 0.5631\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.6762 - acc: 0.5722\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.6736 - acc: 0.5775\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=256, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "iJIdazmmfIMQ",
    "outputId": "63385ac4-5808-405b-a970-7a92a89451f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 1s 2ms/step - loss: 0.6800 - acc: 0.5597\n",
      "Test Accuracy: 0.5597406625747681\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZEVajWs1V3F"
   },
   "source": [
    "C) Adding L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "qTvMCqPZf9QF",
    "outputId": "6769d34c-ba1b-4bf1-d505-fd25064a83d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 32)            3666240   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               328192    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,070,465\n",
      "Trainable params: 404,225\n",
      "Non-trainable params: 3,666,240\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 32, input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "IwhH3pTggd4U",
    "outputId": "7f579391-b1b6-4d69-cc44-a769af14863a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 0.7198 - acc: 0.5356\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 0.6925 - acc: 0.5599\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 0.6849 - acc: 0.5828\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 0.6656 - acc: 0.6276\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 0.6107 - acc: 0.6955\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 0.5201 - acc: 0.7708\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 0.4248 - acc: 0.8330\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 0.3404 - acc: 0.8806\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 0.2821 - acc: 0.9104\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 4s 15ms/step - loss: 0.2406 - acc: 0.9312\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=256, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "SHQcvEHIgCon",
    "outputId": "ae1f79cc-b51a-4102-94c4-d444216f1701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 1s 3ms/step - loss: 1.5470 - acc: 0.5557\n",
      "Test Accuracy: 0.5557336211204529\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTIoIgvN1nz3"
   },
   "source": [
    "D) Trying dropout with L2 regularizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "N5g65_VS0zRf",
    "outputId": "d957b6c2-08cc-47dc-b651-b9dc5901c6a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 20, 32)            3666240   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               328192    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,070,465\n",
      "Trainable params: 404,225\n",
      "Non-trainable params: 3,666,240\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 32, input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "yuIVhyUB1_IA",
    "outputId": "d4dfc8e9-a38e-4b87-b859-8b19948598a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.7360 - acc: 0.5234\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.7017 - acc: 0.5369\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.6958 - acc: 0.5437\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.6940 - acc: 0.5471\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.6933 - acc: 0.5476\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.6933 - acc: 0.5477\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.6923 - acc: 0.5516\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.6926 - acc: 0.5526\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 6s 19ms/step - loss: 0.6925 - acc: 0.5538\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.6928 - acc: 0.5554\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=256, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "hiXZPdHd2XmW",
    "outputId": "60850122-e473-4b08-e462-6031519008c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 1s 2ms/step - loss: 0.6939 - acc: 0.5524\n",
      "Test Accuracy: 0.5523823499679565\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VNmfMTf2a0X"
   },
   "source": [
    "# Model 2\n",
    "Including the Handle feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "Bp484CJe2izO",
    "outputId": "abb9a7e2-c160-470c-cff1-bb3b934ad309"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "unique_handles = train_df.Handle.unique()\n",
    "### map each color to an integer\n",
    "mapping = {}\n",
    "for x in range(len(unique_handles)):\n",
    "  mapping[unique_handles[x]] = x\n",
    "\n",
    "# integer representation\n",
    "for x in range(len(train_df.Handle)):\n",
    "  train_df.Handle[x] = mapping[train_df.Handle[x]]\n",
    "print(to_categorical(train_df.Handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "9Y_7-OoDGuwf",
    "outputId": "11598e7c-63f3-4ccb-9921-c0165d23b578"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "test_df.reset_index(inplace=True)\n",
    "unique_handles = test_df.Handle.unique()\n",
    "### map each color to an integer\n",
    "mapping = {}\n",
    "for x in range(len(unique_handles)):\n",
    "  mapping[unique_handles[x]] = x\n",
    "\n",
    "# integer representation\n",
    "for x in range(len(test_df.Handle)):\n",
    "  test_df.Handle[x] = mapping[test_df.Handle[x]]\n",
    "print(to_categorical(test_df.Handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRL3bJWv4bCq"
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train).merge(pd.DataFrame(to_categorical(train_df.Handle)), left_index=True, right_index=True)\n",
    "X_test = pd.DataFrame(X_test).merge(pd.DataFrame(to_categorical(test_df.Handle)), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "BU9O11YUG6fg",
    "outputId": "5d6b23d9-ddc0-4b48-80da-b9b6d217d15b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72734, 453)\n",
      "(13726, 441)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "ct7vvua_Hk1H",
    "outputId": "dee0a6f4-28ae-4d2f-af2d-8826d4e23dca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>9_x</th>\n",
       "      <th>10_x</th>\n",
       "      <th>11_x</th>\n",
       "      <th>12_x</th>\n",
       "      <th>13_x</th>\n",
       "      <th>14_x</th>\n",
       "      <th>15_x</th>\n",
       "      <th>16_x</th>\n",
       "      <th>17_x</th>\n",
       "      <th>18_x</th>\n",
       "      <th>19_x</th>\n",
       "      <th>0_y</th>\n",
       "      <th>1_y</th>\n",
       "      <th>2_y</th>\n",
       "      <th>3_y</th>\n",
       "      <th>4_y</th>\n",
       "      <th>5_y</th>\n",
       "      <th>6_y</th>\n",
       "      <th>7_y</th>\n",
       "      <th>8_y</th>\n",
       "      <th>9_y</th>\n",
       "      <th>10_y</th>\n",
       "      <th>11_y</th>\n",
       "      <th>12_y</th>\n",
       "      <th>13_y</th>\n",
       "      <th>14_y</th>\n",
       "      <th>15_y</th>\n",
       "      <th>16_y</th>\n",
       "      <th>17_y</th>\n",
       "      <th>18_y</th>\n",
       "      <th>19_y</th>\n",
       "      <th>...</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "      <th>410</th>\n",
       "      <th>411</th>\n",
       "      <th>412</th>\n",
       "      <th>413</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "      <th>418</th>\n",
       "      <th>419</th>\n",
       "      <th>420</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>74</td>\n",
       "      <td>229</td>\n",
       "      <td>680</td>\n",
       "      <td>216</td>\n",
       "      <td>7</td>\n",
       "      <td>20614</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>2245</td>\n",
       "      <td>2672</td>\n",
       "      <td>313</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>501</td>\n",
       "      <td>171</td>\n",
       "      <td>221</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>6836</td>\n",
       "      <td>3165</td>\n",
       "      <td>210</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>1324</td>\n",
       "      <td>48</td>\n",
       "      <td>615</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>32338</td>\n",
       "      <td>636</td>\n",
       "      <td>47</td>\n",
       "      <td>746</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>117</td>\n",
       "      <td>78</td>\n",
       "      <td>1056</td>\n",
       "      <td>5</td>\n",
       "      <td>1726</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>24735</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>192</td>\n",
       "      <td>6225</td>\n",
       "      <td>4506</td>\n",
       "      <td>1483</td>\n",
       "      <td>8</td>\n",
       "      <td>1213</td>\n",
       "      <td>1258</td>\n",
       "      <td>797</td>\n",
       "      <td>303</td>\n",
       "      <td>12</td>\n",
       "      <td>1038</td>\n",
       "      <td>48</td>\n",
       "      <td>3771</td>\n",
       "      <td>2985</td>\n",
       "      <td>11982</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185</td>\n",
       "      <td>174</td>\n",
       "      <td>19</td>\n",
       "      <td>281</td>\n",
       "      <td>1009</td>\n",
       "      <td>242</td>\n",
       "      <td>263</td>\n",
       "      <td>107</td>\n",
       "      <td>3241</td>\n",
       "      <td>10</td>\n",
       "      <td>403</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 441 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_x    1_x   2_x   3_x   4_x  5_x    6_x  ...  414  415  416  417  418  419  420\n",
       "0   89     74   229   680   216    7  20614  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1    1    189   501   171   221   21      4  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2   21  32338   636    47   746   32     38  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3   34    192  6225  4506  1483    8   1213  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4  185    174    19   281  1009  242    263  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[5 rows x 441 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "m_WYLxfSGjOn",
    "outputId": "c5b90c97-93e4-4f9a-d85b-7b46dc63ed10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72734, 453)\n",
      "(13726, 453)\n"
     ]
    }
   ],
   "source": [
    "for x in range(421, 433):\n",
    "    X_test[str(x)] = 0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ox0blefkAuRY"
   },
   "source": [
    "Using the model's architecture that showed highest accuracy in part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "i5ZdHAXP8wqo",
    "outputId": "d63ea4ed-8661-4065-b1c1-1c04638127c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 453, 32)           3666240   \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 14496)             0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 512)               7422464   \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 11,164,737\n",
      "Trainable params: 7,498,497\n",
      "Non-trainable params: 3,666,240\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 32, input_length=X_train.shape[1] , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "aMYx7c1V83zi",
    "outputId": "0187ab97-87f4-44cc-82f9-54db283b0d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "285/285 [==============================] - 44s 153ms/step - loss: 0.6934 - acc: 0.5139\n",
      "Epoch 2/5\n",
      "285/285 [==============================] - 44s 153ms/step - loss: 0.6904 - acc: 0.5270\n",
      "Epoch 3/5\n",
      "285/285 [==============================] - 44s 154ms/step - loss: 0.6364 - acc: 0.6283\n",
      "Epoch 4/5\n",
      "285/285 [==============================] - 43s 152ms/step - loss: 0.3931 - acc: 0.8250\n",
      "Epoch 5/5\n",
      "285/285 [==============================] - 43s 152ms/step - loss: 0.0454 - acc: 0.9929\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=256, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "mRYmlbb5Cn2e",
    "outputId": "a1e5defd-7d94-4ce3-bf30-fca370ddad05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 6s 14ms/step - loss: 0.0665 - acc: 0.9888\n",
      "Test Accuracy: 0.9887804388999939\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXudKmpKKl-5"
   },
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrDybnxDKnmY"
   },
   "source": [
    "In the preprocessing part:\n",
    "1. I followed some NLTK tutorials and the tensorflow's documentation tutorial on dealing with text based data (IMDB movies reviews dataset) to clean the tweets and tokenizing them.\n",
    "2. I usd tensorflow's sequence_pad to pad to generate a fixed-size input. I experminted N=100, 50, 30, and 20. 20 showed the best training accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmaYmaSOKMF8"
   },
   "source": [
    "In part 1 (without using the Handle feature),\n",
    "1. I first experiment a normal feedforward neural network with only 1 hidden layer, then tried increasing the number of layers to add depth to the network and tried different neurons numbers to reach the used model which showed highest training and testing accuracy so far.  \n",
    "**Accuracy for this model: 55.76%.**\n",
    "2. I tried adding Dropout layers after each hidden layer and experimented dropout ratio with 0.2 and 0.5 and found that 0.5 works well with layers having large number of neurons (like the first and second layers) and 0.2 works well with layers having small number of neurons.  \n",
    "**Accuracy for this model: 55.97%.**\n",
    "3. I tried using L2 regularization to all layers with lambda = 0.01, 0.001, and 0.0001 using tensorflow's kernel_regualizer. The 0.0001 showed the best results.\n",
    "**Accuracy for this model: 55.57%.**\n",
    "4. I tried mixing model 2 (with dropout) and model 3 (with L2 regularization) to see if they work better together.  \n",
    "**Accuracy for this model: 55.24%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsfjNgGPNPo_"
   },
   "source": [
    "In part 2 (with the Handle feature):\n",
    "1. I encoded the Handle feature column using tensorflow's to_categorical after giving each unique handle an index.\n",
    "2. I added 0 columns at the end of X_test to match the dimensions of X_train as the model raised an error where they didn't match.\n",
    "3. I tried the 3 different models used in part 1 and the first model (the one with no regularization)showed highest **accuracy: 98.9%**. So, clearly using the Handle feature improves the testing accuracy a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boX8FPQvOJJ4"
   },
   "source": [
    "Other hyperparameters:\n",
    "1. I tried decreasing the learning rate but the model wasn't learning well (training accuracy was hardly increasing). So, I left it at the default 0.001.\n",
    "2. I tried batch_size= 32, 64 but it took some time to train so, I increased it to 256 and the training speed increased noticably without affecting the accuracy.\n",
    "3. I started with ephocs=20 but noticed that most models accuracy don't increase much after the tenth epoch. So, I used ephocs=10 for all part 1 models and ephocs=5 for the part 2 model as it already reaches 100% training accuracy in ephoc 5."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
